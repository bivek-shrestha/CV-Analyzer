{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "poiUReSDo1r6",
        "outputId": "4e65bd3c-2467-4fe6-e2c0-860a2df22591"
      },
      "outputs": [],
      "source": [
        "### This is the Google Colab notebook the neural network was developed in\n",
        "\n",
        "# Install nltk\n",
        "!pip install --user -U nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "vOUgXHY6pAIh",
        "outputId": "1e7a975e-239c-42c8-c120-503c5152fa44"
      },
      "outputs": [],
      "source": [
        "# Import all libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import shuffle\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(precision=4)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "raKtqeIDpBf0",
        "outputId": "4ad883d1-8bc5-46f2-9ed1-f1308de157f3"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('UpdatedResumeDataSet.csv', engine='python')\n",
        "#data = pd.read_csv('/content/drive/My Drive/CodeDay/UpdatedResumeDataSet.csv') # Comment this line and uncomment the above line if this does not work for you\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "colab_type": "code",
        "id": "lQWr0RJRpIQ9",
        "outputId": "489391e8-47b2-410c-cc28-325a6236c6c6"
      },
      "outputs": [],
      "source": [
        "# Print unique categories of resumes\n",
        "print(data['Category'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4ml2WddhpNEl"
      },
      "outputs": [],
      "source": [
        "# Drop rows where category is \"Testing\" and store new size of dataset\n",
        "data = data[data.Category != 'Testing']\n",
        "data_size = len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "colab_type": "code",
        "id": "MgLthsGHpN_6",
        "outputId": "91d68162-b790-426d-d14b-5bb1b7ac02e4"
      },
      "outputs": [],
      "source": [
        "# Bar graph visualization\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.xticks(rotation=90)\n",
        "sns.countplot(y=\"Category\", data=data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xHxRTJ_QpS_o"
      },
      "outputs": [],
      "source": [
        "# Get set of stopwords\n",
        "stopwords_set = set(stopwords.words('english')+['``',\"''\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "81wWgOKYpU1-"
      },
      "outputs": [],
      "source": [
        "# Function to clean resume text\n",
        "def clean_text(resume_text):\n",
        "    resume_text = re.sub('http\\S+\\s*', ' ', resume_text)  # remove URLs\n",
        "    resume_text = re.sub('RT|cc', ' ', resume_text)  # remove RT and cc\n",
        "    resume_text = re.sub('#\\S+', '', resume_text)  # remove hashtags\n",
        "    resume_text = re.sub('@\\S+', '  ', resume_text)  # remove mentions\n",
        "    resume_text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resume_text)  # remove punctuations\n",
        "    resume_text = re.sub(r'[^\\x00-\\x7f]',r' ', resume_text) \n",
        "    resume_text = re.sub('\\s+', ' ', resume_text)  # remove extra whitespace\n",
        "    resume_text = resume_text.lower()  # convert to lowercase\n",
        "    resume_text_tokens = word_tokenize(resume_text)  # tokenize\n",
        "    filtered_text = [w for w in resume_text_tokens if not w in stopwords_set]  # remove stopwords\n",
        "    return ' '.join(filtered_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "colab_type": "code",
        "id": "IKol74xcpWfR",
        "outputId": "5a93b1b2-ce70-4deb-934f-ab8072a09169"
      },
      "outputs": [],
      "source": [
        "# Print a sample original resume\n",
        "print('--- Original resume ---')\n",
        "print(data['Resume'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "colab_type": "code",
        "id": "ixmhpVkfpYH8",
        "outputId": "7ea329d8-b448-4d67-e0e1-2495cb6f3bfe"
      },
      "outputs": [],
      "source": [
        "# Print the same resume after text cleaning\n",
        "data['cleaned_resume'] = data.Resume.apply(lambda x: clean_text(x))\n",
        "\n",
        "print('--- Cleaned resume ---')\n",
        "print(data['cleaned_resume'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "colab_type": "code",
        "id": "OcxDvdYoparS",
        "outputId": "9594bf10-d52c-42b4-d28b-2d569c1795cf"
      },
      "outputs": [],
      "source": [
        "# Get features and labels from data and shuffle\n",
        "features = data['cleaned_resume'].values\n",
        "original_labels = data['Category'].values\n",
        "labels = original_labels[:]\n",
        "\n",
        "for i in range(data_size):\n",
        "  labels[i] = str(labels[i].lower())  # convert to lowercase\n",
        "  labels[i] = labels[i].replace(\" \", \"\")  # use hyphens to convert multi-token labels into single tokens\n",
        "\n",
        "features, labels = shuffle(features, labels)\n",
        "\n",
        "# Print example feature and label\n",
        "print(features[0])\n",
        "print(labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "ymbM9wkVpe7l",
        "outputId": "7af7d2dd-f271-47ae-a2cc-a19c891f4572"
      },
      "outputs": [],
      "source": [
        "# Split for train and test\n",
        "train_split = 0.8\n",
        "train_size = int(train_split * data_size)\n",
        "\n",
        "train_features = features[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "test_features = features[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "# Print size of each split\n",
        "print(len(train_labels))\n",
        "print(len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "siMQvlJapkmZ",
        "outputId": "a0c396a3-1624-46e4-d83d-1cbb361222c8"
      },
      "outputs": [],
      "source": [
        "# Tokenize feature data and print word dictionary\n",
        "vocab_size = 6000\n",
        "oov_tok = '<OOV>'\n",
        "\n",
        "feature_tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "feature_tokenizer.fit_on_texts(features)\n",
        "\n",
        "feature_index = feature_tokenizer.word_index\n",
        "print(dict(list(feature_index.items())))\n",
        "\n",
        "# Print example sequences from train and test datasets\n",
        "train_feature_sequences = feature_tokenizer.texts_to_sequences(train_features)\n",
        "print(train_feature_sequences[0])\n",
        "\n",
        "test_feature_sequences = feature_tokenizer.texts_to_sequences(test_features)\n",
        "print(test_feature_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "colab_type": "code",
        "id": "10PldKNSprXW",
        "outputId": "d52f982b-bfdc-43f8-92fa-037f80bd44ca"
      },
      "outputs": [],
      "source": [
        "# Tokenize label data and print label dictionary\n",
        "label_tokenizer = Tokenizer(lower=True)\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "\n",
        "label_index = label_tokenizer.word_index\n",
        "print(dict(list(label_index.items())))\n",
        "\n",
        "# Print example label encodings from train and test datasets\n",
        "train_label_sequences = label_tokenizer.texts_to_sequences(train_labels)\n",
        "print(train_label_sequences[0])\n",
        "\n",
        "test_label_sequences = label_tokenizer.texts_to_sequences(test_labels)\n",
        "print(test_label_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "colab_type": "code",
        "id": "SvHlL7PXpzBX",
        "outputId": "3bfcfa34-0027-41e6-8e9f-28579d074e33"
      },
      "outputs": [],
      "source": [
        "# Pad sequences for feature data\n",
        "max_length = 300\n",
        "trunc_type = 'post'\n",
        "pad_type = 'post'\n",
        "\n",
        "train_feature_padded = pad_sequences(train_feature_sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
        "test_feature_padded = pad_sequences(test_feature_sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
        "\n",
        "# Print example padded sequences from train and test datasets\n",
        "print(train_feature_padded[0])\n",
        "print(test_feature_padded[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "colab_type": "code",
        "id": "89LGoDoqp39S",
        "outputId": "24fa791a-9d2a-45b9-ec09-71ffc76f2726"
      },
      "outputs": [],
      "source": [
        "# Define the neural network\n",
        "embedding_dim = 64\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # Add an Embedding layer expecting input vocab of size 6000, and output embedding dimension of size 64 we set at the top\n",
        "  tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=1),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "  #tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
        "\n",
        "  # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
        "  tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
        "\n",
        "  # Add a Dense layer with 25 units and softmax activation for probability distribution\n",
        "  tf.keras.layers.Dense(25, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "colab_type": "code",
        "id": "N7lkMhVa2JCV",
        "outputId": "4e5d75ef-f7df-4acf-fab1-918f62fa79ef"
      },
      "outputs": [],
      "source": [
        "# Alternative model\n",
        "embedding_dim = 64\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # Add an Embedding layer expecting input vocab of size 6000, and output embedding dimension of size 64 we set at the top\n",
        "  tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1),\n",
        "  #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
        "  #tf.keras.layers.Flatten(),\n",
        "  #tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.GlobalMaxPooling1D(),\n",
        "\n",
        "\n",
        "  # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  # Add a Dense layer with 25 units and softmax activation for probability distribution\n",
        "  tf.keras.layers.Dense(25, activation='softmax'),\n",
        "  #tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "  #tf.keras.layers.Dense(1)\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BgCN2tjmp8a0"
      },
      "outputs": [],
      "source": [
        "# Compile the model and convert train/test data into NumPy arrays\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Features\n",
        "train_feature_padded = np.array(train_feature_padded)\n",
        "test_feature_padded = np.array(test_feature_padded)\n",
        "\n",
        "# Labels\n",
        "train_label_sequences = np.array(train_label_sequences)\n",
        "test_label_sequences = np.array(test_label_sequences)\n",
        "\n",
        "# Print example values\n",
        "#print(train_feature_padded[0])\n",
        "#print(train_label_sequences[0])\n",
        "#print(test_feature_padded[0])\n",
        "#print(test_label_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "colab_type": "code",
        "id": "HjkpyftMp_gj",
        "outputId": "c7f0aab6-d5db-4286-e4aa-0e805de3eaad"
      },
      "outputs": [],
      "source": [
        "# Train the neural network\n",
        "num_epochs = 12\n",
        "\n",
        "history = model.fit(train_feature_padded, train_label_sequences, epochs=num_epochs, validation_data=(test_feature_padded, test_label_sequences), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "colab_type": "code",
        "id": "YfTvLMAKqpWV",
        "outputId": "b4d3ad7d-13bb-4aa4-b088-ad476f38157d"
      },
      "outputs": [],
      "source": [
        "# print example feature and its correct label\n",
        "print(test_features[5])\n",
        "print(test_labels[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "colab_type": "code",
        "id": "DAqRBYLsqsS3",
        "outputId": "83e126cd-f50d-4259-ea24-a449b6e005d0"
      },
      "outputs": [],
      "source": [
        "# Create padded sequence for example\n",
        "resume_example = 'skills bitcoin ethereum solidity hyperledger beginner go beginner r3 corda beginner tendermint nodejs c programming java machine learning specilaized brain computer interface computer networking server admin computer vision data analytics cloud computing reactjs angulareducation details january 2014 january 2018 bachelor engineering computer science engineering thakur college engineering technology september 2016 march 2017 dynamic blood bank system mumbai maharashtra iit january 2014 cbse senior secondary january 2011 cbse banking vidyashram public school blockchain developer blockchain developer zhypility technologies skill details networking exprience 27 months data analytics exprience 11 months computer vision exprience 6 months java exprience 6 months machine learning exprience 6 monthscompany details company zhypility technologies description une 2018 company area business owner amway enterprise limited description business strategizing promotion analytics networking terms company virtual description developing prototype smart india hackthon deployment level 3 networking switch intern bharti airtel private limited mumbai company 1 international research scholar university rome tor vergata rome description nov 2017 nov 2017 done research reality based brain computer interface proposed paper international journal advanced research ijar 20656 epted paper reviewer smart kisan revolutionizing country ijsrd epted publication company description reliance jio mumbai dec 2017 jan 2017 company maharastra state government hackthon description company virtual description handling group interns marketing sales team nearby promote social media platform nearby products company promotion stock marketing drums foods international description company 8 data science web analytics positron internet virtual description company description making people aware women equality rights raise voice violence various modes events sources media help society company iit bombay iit kgp startup description company iit bombay iit kgp startup description'\n",
        "example_sequence = feature_tokenizer.texts_to_sequences([resume_example])\n",
        "example_padded = pad_sequences(example_sequence, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n",
        "example_padded = np.array(example_padded)\n",
        "print(example_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "hIKf8crUq8wx",
        "outputId": "6716a2a2-f21f-48ea-ab0a-88258e90610c"
      },
      "outputs": [],
      "source": [
        "# Make a prediction\n",
        "prediction = model.predict(example_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "colab_type": "code",
        "id": "OWYVziHMrCav",
        "outputId": "2db6b430-28c9-4af9-f70e-03110eb4d85b"
      },
      "outputs": [],
      "source": [
        "# Verify that prediction has correct format\n",
        "print(prediction[0])\n",
        "print(len(prediction[0]))  # should be 25\n",
        "print(np.sum(prediction[0]))  # should be 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "7yf4KnNjrGcV",
        "outputId": "d6b9d6c1-22a9-491f-d4a0-ef71c1308f6a"
      },
      "outputs": [],
      "source": [
        "# Find maximum value in prediction and its index\n",
        "print(max(prediction[0]))  # confidence in prediction (as a fraction of 1)\n",
        "print(np.argmax(prediction[0])) # should be 11 which corresponds to blockchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "Y-DNi39XxqCN",
        "outputId": "8943e6fd-2b9d-454a-c844-d78cf5f7370c"
      },
      "outputs": [],
      "source": [
        "# Indices of top 5 most probable solutions\n",
        "indices = np.argpartition(prediction[0], -5)[-5:]\n",
        "indices = indices[np.argsort(prediction[0][indices])]\n",
        "indices = list(reversed(indices))\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "pRxAe_QkrW_2",
        "outputId": "4c87cc23-bec2-4e6c-cb90-02a9faf9d109"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save('model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Xo584Smdr4ps"
      },
      "outputs": [],
      "source": [
        "# Save feature tokenizer\n",
        "with open('feature_tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(feature_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "colab_type": "code",
        "id": "Ul39OZ10sJCC",
        "outputId": "7d559e88-a74e-460a-9b48-b6a2291cf54a"
      },
      "outputs": [],
      "source": [
        "# Save reverse dictionary of labels to encodings\n",
        "label_to_encoding = dict(list(label_index.items()))\n",
        "print(label_to_encoding)\n",
        "\n",
        "encoding_to_label = {}\n",
        "for k, v in label_to_encoding.items():\n",
        "  encoding_to_label[v] = k\n",
        "print(encoding_to_label)\n",
        "\n",
        "with open('dictionary.pickle', 'wb') as handle:\n",
        "    pickle.dump(encoding_to_label, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "7rFzn7JcuOVz",
        "outputId": "8a260e0d-7e34-46c6-8bbb-26f4becf98e4"
      },
      "outputs": [],
      "source": [
        "print(encoding_to_label[np.argmax(prediction[0])])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Neural_Network_CodeDay_Resume_Screening.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "5495759e2c1662876d0f116a64e0979e2ad19c6d9574897aa392083d01843168"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
